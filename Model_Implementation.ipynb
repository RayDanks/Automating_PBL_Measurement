{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zsPjo1UzjK-"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glbLkvg-zluN"
      },
      "outputs": [],
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "import tensorflow.compat.v1.keras\n",
        "from tensorflow.compat.v1.keras.layers import *\n",
        "from tensorflow.compat.v1.keras.models import *\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import glob\n",
        "import tensorflow.compat.v1.keras.backend as K\n",
        "\n",
        "import sys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ag4sBKCzDGtx"
      },
      "source": [
        "Importing a single image such that we can TEST the network (find its output sizes etc etc)\n",
        "\n",
        "we show two different hourglasses (one from KNEEL paper and one from our paper, the latter which is used for final results) and use the entry and exit blocks from the cited KNEEL paper (A Tiulpin et al)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoHGNyhhwloO"
      },
      "outputs": [],
      "source": [
        "def HMP_Block(input_size,output_size):\n",
        "  m = output_size\n",
        "  n = input_size[-1]\n",
        "  inputs = Input((None,None,n))\n",
        "\n",
        "  padded_inputs = ZeroPadding2D(padding=(1, 1))(inputs)\n",
        "  x = Conv2D(int(m/2),kernel_size = (3,3), activation = 'relu', name = \"HMP_1\")(padded_inputs)\n",
        "  x = BatchNormalization()(x)\n",
        "  y = ZeroPadding2D(padding=(1, 1))(x)\n",
        "  y = Conv2D(int(m/4),kernel_size = (3,3), activation = 'relu',name = \"HMP_2\")(y)\n",
        "  y = BatchNormalization()(y)\n",
        "\n",
        "  z = ZeroPadding2D(padding=(1, 1))(y)\n",
        "  z = Conv2D(int(m/4),kernel_size = (3,3), activation = 'relu',name = \"HMP_3\")(z)\n",
        "  z = BatchNormalization()(z)\n",
        "\n",
        "  concat = Concatenate()([x,y,z])\n",
        "\n",
        "\n",
        "  #must be here to make block versatile to input sizes.\n",
        "  if (n != m):\n",
        "    skip = Conv2D(m,kernel_size = (1,1), activation = 'relu', name = \"HMP_skip\")(inputs) #don't need to pad since if it convolutes it's 1x1 anyway\n",
        "  else:\n",
        "    skip = Lambda(lambda x: x)(inputs)\n",
        "\n",
        "\n",
        "  addition = Add()([skip,concat])\n",
        "\n",
        "  model = Model(inputs,addition)\n",
        "  return model\n",
        "\n",
        "\n",
        "def Hourglass_Block(input_size,depth,width,upsampling):\n",
        "  mid_output_list = []\n",
        "  up = upsampling\n",
        "  inputs = Input(input_size)\n",
        "  #downsampling loop\n",
        "  for i in range(depth):\n",
        "    #first section\n",
        "    if i == 0:\n",
        "      pooled = MaxPooling2D(pool_size = 2)(inputs)\n",
        "    else:\n",
        "      #should be the output of the previous end of start\n",
        "      # print(\"end of start\",end_of_start)\n",
        "      pooled = MaxPooling2D(pool_size = 2)(end_of_start)\n",
        "\n",
        "    #three blocks now\n",
        "    x = HMP_Block(pooled.shape[1:],width*4)(pooled)\n",
        "    x = HMP_Block(x.shape[1:],width*4)(x)\n",
        "    end_of_start = HMP_Block(x.shape[1:],width*4)(x)\n",
        "\n",
        "    #now we begin the middle section\n",
        "    #each iteration has its own middle section\n",
        "    x = HMP_Block(end_of_start.shape[1:],width*4)(end_of_start)\n",
        "    if i != depth-1: #the bottom layer has one less HMP\n",
        "      x = HMP_Block(x.shape[1:],width*4)(x)\n",
        "    end_of_mid = HMP_Block(x.shape[1:],width*8)(x)\n",
        "    mid_output_list.append(end_of_mid) #we use these results in addition in the upsample section\n",
        "\n",
        "  mid_output_list.reverse() #list is now in reverse order\n",
        "\n",
        "  #upsampling loop\n",
        "  final_j = len(mid_output_list) -1 #how the indexing and length works\n",
        "  for j, output_of_mid in enumerate(mid_output_list):\n",
        "    if j == final_j:\n",
        "      break #the way that the algorithm works, at the current layer, it upsample and adds to the above layer,\n",
        "      #so when we reach the top, the output of the addition of the top layer and the upsample is already known.\n",
        "      #This is the outpout of the hourglass\n",
        "    \n",
        "    desired_x, desired_y = mid_output_list[j+1].shape[1:3] #find the size of the layer above's image\n",
        "    if j == 0:\n",
        "      current_x,current_y = output_of_mid.shape[1:3] #current layer's image shape\n",
        "    else:\n",
        "      current_x,current_y = addition_after.shape[1:3] #current layer's image shape\n",
        "\n",
        "    upsample_x_factor = int(int(desired_x)/int(current_x))\n",
        "    upsample_y_factor = int(int(desired_y)/int(current_y))\n",
        "\n",
        "\n",
        "    if j == 0:\n",
        "      upsampled = UpSampling2D(size = (upsample_x_factor,upsample_y_factor),interpolation = up)(output_of_mid) #this inputs[1:2] part may be wrong.\n",
        "    else:\n",
        "      upsampled = UpSampling2D(size = (upsample_x_factor,upsample_y_factor),interpolation = up)(addition_after) #recursive\n",
        "\n",
        "\n",
        "    #now we have the initial \"seed\" upsample, we can begin the addition process\n",
        "    next_mid_out = mid_output_list[j+1] #layer above's mid output\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    So since Keras' upsampling uses an integer multiplying factor,\n",
        "    sometimes the upsampled ikmage will not be the exact correct size \n",
        "    (usually one off), therefore we should assymetrically pad it\n",
        "    \"\"\"\n",
        "    if upsampled.shape[1] != next_mid_out.shape[1]:\n",
        "      upsampled = ZeroPadding2D(padding=((1, 0),(0,0)))(upsampled) #pad the top\n",
        "    if upsampled.shape[2] != next_mid_out.shape[2]:\n",
        "      upsampled = ZeroPadding2D(padding=((0, 0),(0,1)))(upsampled) #pad the right\n",
        "\n",
        "    addition = Add()([upsampled,next_mid_out])\n",
        "\n",
        "    if j != final_j -1: #when we're on the second-top layer,there is no 8N block after the upsample tok the above layer.\n",
        "      addition_after = HMP_Block(addition.shape[1:],width*8)(addition)#after the 8N residual block\n",
        "    else:\n",
        "      outputs = addition #for unique output\n",
        "\n",
        "  model = Model(inputs,outputs)\n",
        "  return model\n",
        "\n",
        "\"\"\"\n",
        "In order to be able to stack the hourglasses, they must be symmetric, as they are in the\n",
        "stacked paper - however, in the KNEEL paper they are not symmetric and hence must be\n",
        "adjusted here. This is the difference with our hourglass\n",
        "\"\"\"\n",
        "\n",
        "def Symmetric_Hourglass_Block(input_size,depth,width,upsampling,name=\"symmetricHourglass\"):\n",
        "  mid_output_list = []\n",
        "  up = upsampling\n",
        "  inputs = Input(input_size)\n",
        "  #downsampling loop\n",
        "  for i in range(depth):\n",
        "    #first section\n",
        "    if i == 0: #the image input to the hourglass\n",
        "      x = HMP_Block(input_size,width*4)(inputs)\n",
        "      x = HMP_Block(x.shape[1:],width*4)(x)\n",
        "      input_image_mid_end = HMP_Block(x.shape[1:],width*8)(x)\n",
        "      mid_output_list.append(input_image_mid_end)\n",
        "      pooled = MaxPooling2D(pool_size = 2)(input_image_mid_end) #now we just start the general looping for downsampling\n",
        "    else:\n",
        "      #should be the output of the previous end of start\n",
        "      pooled = MaxPooling2D(pool_size = 2)(end_of_start)\n",
        "\n",
        "    #three blocks now\n",
        "    x = HMP_Block(pooled.shape[1:],width*4)(pooled)\n",
        "    x = HMP_Block(x.shape[1:],width*4)(x)\n",
        "    end_of_start = HMP_Block(x.shape[1:],width*4)(x)\n",
        "\n",
        "    #now we begin the middle section\n",
        "    #each iteration has its own middle section\n",
        "    x = HMP_Block(end_of_start.shape[1:],width*4)(end_of_start)\n",
        "    if i != depth-1: #the bottom layer has one less HMP\n",
        "      x = HMP_Block(x.shape[1:],width*4)(x)\n",
        "    end_of_mid = HMP_Block(x.shape[1:],width*8)(x)\n",
        "    mid_output_list.append(end_of_mid) #we use these results in addition in the upsample section\n",
        "\n",
        "  mid_output_list.reverse() #list is now in reverse order\n",
        "\n",
        "  #upsampling loop\n",
        "  final_j = len(mid_output_list) -1 #how the indexing and length works\n",
        "  for j, output_of_mid in enumerate(mid_output_list):\n",
        "    if j == final_j:\n",
        "      break #the way that the algorithm works, at the current layer, it upsample and adds to the above layer,\n",
        "      #so when we reach the top, the output of the addition of the top layer and the upsample is already known.\n",
        "      #This is the outpout of the hourglass\n",
        "    \n",
        "    desired_x, desired_y = mid_output_list[j+1].shape[1:3] #find the size of the layer above's image\n",
        "    if j == 0:\n",
        "      current_x,current_y = output_of_mid.shape[1:3] #current layer's image shape\n",
        "    else:\n",
        "      current_x,current_y = addition_after.shape[1:3] #current layer's image shape\n",
        "\n",
        "    upsample_x_factor = int(int(desired_x)/int(current_x))\n",
        "    upsample_y_factor = int(int(desired_y)/int(current_y))\n",
        "\n",
        "\n",
        "    if j == 0:\n",
        "      upsampled = UpSampling2D(size = (upsample_x_factor,upsample_y_factor),interpolation = up)(output_of_mid) #this inputs[1:2] part may be wrong.\n",
        "    else:\n",
        "      upsampled = UpSampling2D(size = (upsample_x_factor,upsample_y_factor),interpolation = up)(addition_after) #recursive\n",
        "\n",
        "\n",
        "    #now we have the initial \"seed\" upsample, we can begin the addition process\n",
        "    next_mid_out = mid_output_list[j+1] #layer above's mid output\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    So since Keras' upsampling uses an integer multiplying factor,\n",
        "    sometimes the upsampled ikmage will not be the exact correct size \n",
        "    (usually one off), therefore we should assymetrically pad it\n",
        "    \"\"\"\n",
        "    if upsampled.shape[1] != next_mid_out.shape[1]:\n",
        "      upsampled = ZeroPadding2D(padding=((1, 0),(0,0)))(upsampled) #pad the top\n",
        "    if upsampled.shape[2] != next_mid_out.shape[2]:\n",
        "      upsampled = ZeroPadding2D(padding=((0, 0),(0,1)))(upsampled) #pad the right\n",
        "\n",
        "    addition = Add()([upsampled,next_mid_out])\n",
        "\n",
        "    if j != final_j -1: #when we're on the second-top layer,there is no 8N block after the upsample tok the above layer.\n",
        "      addition_after = HMP_Block(addition.shape[1:],width*8)(addition)#after the 8N residual block\n",
        "    else:\n",
        "      outputs = addition #for unique output\n",
        "\n",
        "  model = Model(inputs,outputs,name=name)\n",
        "  return model\n",
        "\n",
        "\n",
        "def KNEEL_Entry_Block(input_size,width,name=\"entryBlock\"):\n",
        "  inputs = Input(input_size)\n",
        "  x = Conv2D(width,kernel_size = (7,7), activation = 'relu', name = \"initial_conv\")(inputs)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = HMP_Block(x.shape[1:],2*width)(x)\n",
        "  x = MaxPooling2D(pool_size = 2)(x)\n",
        "  x = HMP_Block(x.shape[1:],2*width)(x)\n",
        "  x = HMP_Block(x.shape[1:],2*width)(x)\n",
        "  x = HMP_Block(x.shape[1:],4*width)(x)\n",
        "  outputs = x\n",
        "  model = Model(inputs,outputs,name=name)\n",
        "  return model\n",
        "\n",
        "def Soft_Argmax(input_size, beta = 1,name=\"softArgmax\"):\n",
        "   #inputs in form: batch size, height, width, channels\n",
        "    inputs = Input(input_size)\n",
        "    new_inputs = inputs * beta\n",
        "    batch, height, width, channels = new_inputs.shape\n",
        "\n",
        "    #transpose tensor such that the channels are first:\n",
        "    transpose = tf.transpose(new_inputs,[0,3,1,2]) #batch, channels, height, width\n",
        "\n",
        "    #now reshape the system\n",
        "    #first source has different shape to second one - going for the deep pipeline as it makes more sense\n",
        "    reshape = K.reshape(transpose,(-1,channels, height*width)) #essentially flattening image - batch needs -1 as it is unknown\n",
        "    softmax = tf.cast(K.reshape(K.softmax(reshape, axis = 2),(-1,channels,height,width)),dtype=tf.float64) #softmax the image coordinate axis\n",
        "\n",
        "    original_size = K.reshape(softmax,(-1,channels,height,width))\n",
        "    original = tf.transpose(original_size, [0,2,3,1]) #reshape to original size - batch,height,width,channels\n",
        "\n",
        "    #create weight tensor of ones the same shape as image\n",
        "    #using channels first so that the H*W is at the end!\n",
        "    weights = K.ones_like(original_size,dtype=tf.float64)\n",
        "\n",
        "    weights_x = tf.math.divide(tf.range(width),width)\n",
        "    weights_x = tf.cast(tf.math.multiply(weights_x,weights),dtype=tf.float64) #element-wise multiplication\n",
        "\n",
        "    weights_y = tf.math.divide(tf.range(height),height)\n",
        "    weights_y = tf.transpose(tf.math.multiply(weights_y,tf.transpose(weights,[0,1,3,2])),[0,1,3,2]) # #NEED TO ADD SOME TRANSPOSES IN ??\n",
        "\n",
        "    approx_x = K.reshape(tf.math.multiply(softmax,weights_x),(-1,channels, height*width))\n",
        "    approx_x = tf.reduce_sum(approx_x,2) #sum and reduce the second axis, so we have batch x channels*1\n",
        "\n",
        "    approx_y = K.reshape(tf.math.multiply(softmax,weights_y),(-1,channels, height*width))\n",
        "    approx_y = tf.reduce_sum(approx_y,2)\n",
        "\n",
        "    #want to make it of size btahc x channels * 2 (for coordinates), therefore:\n",
        "    amount_of_points = int(approx_x.shape[-1])\n",
        "    approx_x = tf.expand_dims(approx_x,-1) #makes it so we have a column for x and a column for y, and then we can flatten for x1,y1,x2,y2,...\n",
        "    approx_y = tf.expand_dims(approx_y,-1)\n",
        "    conc_x_y = tf.concat([approx_x,approx_y],2)\n",
        "    flattened_coords = tf.reshape(conc_x_y,(-1,amount_of_points * 2)) #multiply by 2 for x and y\n",
        "    outputs = flattened_coords\n",
        "    model = Model(inputs,outputs,name=name)\n",
        "    return model\n",
        "\n",
        "\n",
        "def KNEEL_Output_Block(input_size,width,number_of_outputs, name=\"outputBlock\",drop_rate=0.25):\n",
        "  inputs = Input(input_size)\n",
        "  x = SpatialDropout2D(drop_rate)(inputs)\n",
        "  x = tf.cast(x,dtype = tf.float32)\n",
        "  x = Conv2D(8*width,(1,1),activation = 'relu')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = SpatialDropout2D(drop_rate)(x)\n",
        "  x = tf.cast(x,dtype = tf.float32)\n",
        "  x = Conv2D(4*width,(1,1),activation = 'relu')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  outputs = x #removed soft argmax and final conv\n",
        "  model = Model(inputs,outputs,name=name)\n",
        "  return model\n",
        "\n",
        "\n",
        "def KNEEL(input_size,number_of_outputs,depth,width,upsampling):\n",
        "    up = upsampling\n",
        "    inputs = Input(input_size)\n",
        "    cast_inputs = tf.cast(inputs,tf.float32)\n",
        "    x = KNEEL_Entry_Block(input_size,width = width)(cast_inputs)\n",
        "    x = Hourglass_Block = Hourglass_Block(x.shape[1:],\n",
        "                                          depth = depth,\n",
        "                                          width = width,\n",
        "                                          upsampling = upsampling)(x)\n",
        "    x = KNEEL_Output_Block(input_size = x.shape[1:],width = width ,number_of_outputs=number_of_outputs)(x)\n",
        "    outputs = x\n",
        "    model = Model(inputs,outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "def Symmetric_PBL_Network(input_size,number_of_outputs,depth,width,upsampling,name=\"symmetricPBL\"):\n",
        "    up = upsampling\n",
        "    inputs = Input(input_size)\n",
        "    cast_inputs = tf.cast(inputs,tf.float32)\n",
        "    x = KNEEL_Entry_Block(input_size,width = width)(cast_inputs)\n",
        "    x = Hourglass_Block = Symmetric_Hourglass_Block(x.shape[1:],\n",
        "                                                    depth = depth,\n",
        "                                                    width = width,\n",
        "                                                    upsampling = upsampling)(x)\n",
        "    x = KNEEL_Output_Block(input_size = x.shape[1:],width = width ,number_of_outputs=number_of_outputs)(x)\n",
        "    x = Conv2D(number_of_outputs,(1,1),input_size=x.shape[1:])(x)\n",
        "    x = Soft_Argmax(x.shape[1:])(x)\n",
        "    outputs = x\n",
        "    model = Model(inputs,outputs,name=name)\n",
        "    return model\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Model_Implementation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}